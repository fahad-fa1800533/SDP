{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"F-S_ts1TbYyW"},"outputs":[],"source":["import argparse\n","import os\n","import numpy as np\n","from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n","from keras.layers import add, concatenate\n","from keras.models import Model\n","import struct\n","import cv2"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJL5itWA8pdn","executionInfo":{"status":"ok","timestamp":1684165428650,"user_tz":-180,"elapsed":52030,"user":{"displayName":"Khalid AL Otaibi","userId":"17089391293442927573"}},"outputId":"71d6bcb2-da32-4a65-c955-430ff0462a8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\n","\n","# np.set_printoptions(threshold=np.nan)\n","# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","\n","# argparser = argparse.ArgumentParser(\n","#     description='test yolov3 network with coco weights')\n","\n","# argparser.add_argument(\n","#     '-w',\n","#     '--weights',\n","#     help='path to weights file')\n","\n","# argparser.add_argument(\n","#     '-i',\n","#     '--image',\n","#     help='path to image file')\n","\n","class WeightReader:\n","    def __init__(self, weight_file):\n","        with open(weight_file, 'rb') as w_f:\n","            major,    = struct.unpack('i', w_f.read(4))\n","            minor,    = struct.unpack('i', w_f.read(4))\n","            revision, = struct.unpack('i', w_f.read(4))\n","\n","            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n","                w_f.read(8)\n","            else:\n","                w_f.read(4)\n","\n","            transpose = (major > 1000) or (minor > 1000)\n","            \n","            binary = w_f.read()\n","\n","        self.offset = 0\n","        self.all_weights = np.frombuffer(binary, dtype='float32')\n","        \n","    def read_bytes(self, size):\n","        self.offset = self.offset + size\n","        return self.all_weights[self.offset-size:self.offset]\n","\n","    def load_weights(self, model):\n","        for i in range(106):\n","            try:\n","                conv_layer = model.get_layer('conv_' + str(i))\n","                print(\"loading weights of convolution #\" + str(i))\n","\n","                if i not in [81, 93, 105]:\n","                    norm_layer = model.get_layer('bnorm_' + str(i))\n","\n","                    size = np.prod(norm_layer.get_weights()[0].shape)\n","\n","                    beta  = self.read_bytes(size) # bias\n","                    gamma = self.read_bytes(size) # scale\n","                    mean  = self.read_bytes(size) # mean\n","                    var   = self.read_bytes(size) # variance            \n","\n","                    weights = norm_layer.set_weights([gamma, beta, mean, var])  \n","\n","                if len(conv_layer.get_weights()) > 1:\n","                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n","                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n","                    \n","                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n","                    kernel = kernel.transpose([2,3,1,0])\n","                    conv_layer.set_weights([kernel, bias])\n","                else:\n","                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n","                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n","                    kernel = kernel.transpose([2,3,1,0])\n","                    conv_layer.set_weights([kernel])\n","            except ValueError:\n","                print(\"no convolution #\" + str(i))     \n","    \n","    def reset(self):\n","        self.offset = 0\n","\n","class BoundBox:\n","    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n","        self.xmin = xmin\n","        self.ymin = ymin\n","        self.xmax = xmax\n","        self.ymax = ymax\n","        \n","        self.objness = objness\n","        self.classes = classes\n","\n","        self.label = -1\n","        self.score = -1\n","\n","    def get_label(self):\n","        if self.label == -1:\n","            self.label = np.argmax(self.classes)\n","        \n","        return self.label\n","    \n","    def get_score(self):\n","        if self.score == -1:\n","            self.score = self.classes[self.get_label()]\n","            \n","        return self.score\n","\n","def _conv_block(inp, convs, skip=True):\n","    x = inp\n","    count = 0\n","    \n","    for conv in convs:\n","        if count == (len(convs) - 2) and skip:\n","            skip_connection = x\n","        count += 1\n","        \n","        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n","        x = Conv2D(conv['filter'], \n","                   conv['kernel'], \n","                   strides=conv['stride'], \n","                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n","                   name='conv_' + str(conv['layer_idx']), \n","                   use_bias=False if conv['bnorm'] else True)(x)\n","        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n","        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n","\n","    return add([skip_connection, x]) if skip else x\n","\n","def _interval_overlap(interval_a, interval_b):\n","    x1, x2 = interval_a\n","    x3, x4 = interval_b\n","\n","    if x3 < x1:\n","        if x4 < x1:\n","            return 0\n","        else:\n","            return min(x2,x4) - x1\n","    else:\n","        if x2 < x3:\n","             return 0\n","        else:\n","            return min(x2,x4) - x3          \n","\n","def _sigmoid(x):\n","    return 1. / (1. + np.exp(-x))\n","\n","def bbox_iou(box1, box2):\n","    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n","    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n","    \n","    intersect = intersect_w * intersect_h\n","\n","    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n","    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n","    \n","    union = w1*h1 + w2*h2 - intersect\n","    \n","    return float(intersect) / union\n","\n","def make_yolov3_model():\n","    input_image = Input(shape=(None, None, 3))\n","\n","    # Layer  0 => 4\n","    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n","                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n","                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n","                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n","\n","    # Layer  5 => 8\n","    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n","                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n","                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n","\n","    # Layer  9 => 11\n","    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n","                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n","\n","    # Layer 12 => 15\n","    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n","                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n","                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n","\n","    # Layer 16 => 36\n","    for i in range(7):\n","        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n","                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n","        \n","    skip_36 = x\n","        \n","    # Layer 37 => 40\n","    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n","                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n","                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n","\n","    # Layer 41 => 61\n","    for i in range(7):\n","        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n","                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n","        \n","    skip_61 = x\n","        \n","    # Layer 62 => 65\n","    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n","                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n","                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n","\n","    # Layer 66 => 74\n","    for i in range(3):\n","        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n","                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n","        \n","    # Layer 75 => 79\n","    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n","                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n","                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n","                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n","                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n","\n","    # Layer 80 => 82\n","    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n","                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n","\n","    # Layer 83 => 86\n","    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n","    x = UpSampling2D(2)(x)\n","    x = concatenate([x, skip_61])\n","\n","    # Layer 87 => 91\n","    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n","                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n","                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n","                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n","                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n","\n","    # Layer 92 => 94\n","    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n","                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n","\n","    # Layer 95 => 98\n","    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n","    x = UpSampling2D(2)(x)\n","    x = concatenate([x, skip_36])\n","\n","    # Layer 99 => 106\n","    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n","                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n","                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n","                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n","                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n","                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n","                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n","\n","    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n","    return model\n","\n","def preprocess_input(image, net_h, net_w):\n","    new_h, new_w, _ = image.shape\n","\n","    # determine the new size of the image\n","    if (float(net_w)/new_w) < (float(net_h)/new_h):\n","        new_h = (new_h * net_w)/new_w\n","        new_w = net_w\n","    else:\n","        new_w = (new_w * net_h)/new_h\n","        new_h = net_h\n","    new_h=np.round(new_h)\n","    new_w=np.round(new_w)\n","    # resize the image to the new size\n","    resized = cv2.resize(image[:,:,::-1]/255., (int(new_w), int(new_h)))\n","\n","    # embed the image into the standard letter box\n","    new_image = np.ones((net_h, net_w, 3)) * 0.5\n","    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n","    new_image = np.expand_dims(new_image, 0)\n","\n","    return new_image\n","\n","def decode_netout(netout, anchors, obj_thresh, nms_thresh, net_h, net_w):\n","    grid_h, grid_w = netout.shape[:2]\n","    nb_box = 3\n","    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n","    nb_class = netout.shape[-1] - 5\n","\n","    boxes = []\n","\n","    netout[..., :2]  = _sigmoid(netout[..., :2])\n","    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n","    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n","    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n","\n","    for i in range(grid_h*grid_w):\n","        row = i / grid_w\n","        col = i % grid_w\n","        \n","        for b in range(nb_box):\n","            # 4th element is objectness score\n","            objectness = netout[int(row)][int(col)][b][4]\n","            #objectness = netout[..., :4]\n","            \n","            if(objectness.all() <= obj_thresh): continue\n","            \n","            # first 4 elements are x, y, w, and h\n","            x, y, w, h = netout[int(row)][int(col)][b][:4]\n","\n","            x = (col + x) / grid_w # center position, unit: image width\n","            y = (row + y) / grid_h # center position, unit: image height\n","            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n","            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height  \n","            \n","            # last elements are class probabilities\n","            classes = netout[int(row)][col][b][5:]\n","            \n","            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n","            #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n","\n","            boxes.append(box)\n","\n","    return boxes\n","\n","def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n","    if (float(net_w)/image_w) < (float(net_h)/image_h):\n","        new_w = net_w\n","        new_h = (image_h*net_w)/image_w\n","    else:\n","        new_h = net_w\n","        new_w = (image_w*net_h)/image_h\n","        \n","    for i in range(len(boxes)):\n","        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n","        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n","        \n","        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n","        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n","        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n","        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n","        \n","def do_nms(boxes, nms_thresh):\n","    if len(boxes) > 0:\n","        nb_class = len(boxes[0].classes)\n","    else:\n","        return\n","        \n","    for c in range(nb_class):\n","        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n","\n","        for i in range(len(sorted_indices)):\n","            index_i = sorted_indices[i]\n","\n","            if boxes[index_i].classes[c] == 0: continue\n","\n","            for j in range(i+1, len(sorted_indices)):\n","                index_j = sorted_indices[j]\n","\n","                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n","                    boxes[index_j].classes[c] = 0\n","                    \n","def draw_boxes(image, boxes, labels, obj_thresh):\n","    for box in boxes:\n","        label_str = ''\n","        label = -1\n","        \n","        for i in range(len(labels)):\n","            if box.classes[i] > obj_thresh:\n","                label_str += labels[i]\n","                label = i\n","                print(labels[i] + ': ' + str(box.classes[i]*100) + '%')\n","                \n","        if label >= 0:\n","            cv2.rectangle(image, (box.xmin,box.ymin), (box.xmax,box.ymax), (0,255,0), 3)\n","            cv2.putText(image, \n","                        label_str + ' ' + str(box.get_score()), \n","                        (box.xmin, box.ymin - 13), \n","                        cv2.FONT_HERSHEY_SIMPLEX, \n","                        1e-3 * image.shape[0], \n","                        (0,255,0), 2)\n","        \n","    return image      \n","\n","\n","\n","weights_path = '/content/drive/MyDrive/vehicle detection/weights/yolov3.weights'\n","image_path =  '/content/drive/MyDrive/vehicle detection/weights/img4.jpg'\n","\n","# set some parameters\n","net_h, net_w = 416, 416\n","obj_thresh, nms_thresh = 0.5, 0.45\n","anchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\n","labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n","          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n","          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n","          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n","          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n","          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n","          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n","          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n","          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n","          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n","\n","# make the yolov3 model to predict 80 classes on COCO\n","yolov3 = make_yolov3_model()\n","\n","# load the weights trained on COCO into the model\n","weight_reader = WeightReader(weights_path)\n","weight_reader.load_weights(yolov3)\n","\n","# preprocess the image\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"gR9VfMVK8iWF","executionInfo":{"status":"error","timestamp":1684171760050,"user_tz":600,"elapsed":409,"user":{"displayName":"junfer ingaran","userId":"13812787566754558446"}},"outputId":"27fb7f68-3295-4044-e7b1-34a00e54410b"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-7111fd4dfb22>\u001b[0m in \u001b[0;36m<cell line: 394>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;31m# make the yolov3 model to predict 80 classes on COCO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m \u001b[0myolov3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_yolov3_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;31m# load the weights trained on COCO into the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-7111fd4dfb22>\u001b[0m in \u001b[0;36mmake_yolov3_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_yolov3_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Layer  0 => 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"]}]},{"cell_type":"code","source":["image_path   = '/content/drive/MyDrive/vehicle detection/weights/B.jpg'\n","image = cv2.imread(image_path)\n","image_h, image_w, _ = image.shape\n","new_image = preprocess_input(image, net_h, net_w)\n","\n","# run the prediction\n","yolos = yolov3.predict(new_image)\n","boxes = []\n","\n","for i in range(len(yolos)):\n","    # decode the output of the network\n","    boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh, nms_thresh, net_h, net_w)\n","\n","# correct the sizes of the bounding boxes\n","correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n","\n","# suppress non-maximal boxes\n","do_nms(boxes, nms_thresh)     \n","\n","# draw bounding boxes on the image using labels\n","draw_boxes(image, boxes, labels, obj_thresh) \n","\n","# write the image with bounding boxes to file\n","# cv2.imwrite(image_path[:-4] + '_detected' + image_path[-4:], (image).astype('uint8')) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"waRfK9jJ9ue6","executionInfo":{"status":"ok","timestamp":1681560776976,"user_tz":-210,"elapsed":7558,"user":{"displayName":"Hadi Vaezi","userId":"08960764307584402497"}},"outputId":"9e908eae-37ae-414a-db62-7f101a3ecb0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 1s/step\n","car: 99.08249378204346%\n","car: 99.85193014144897%\n","car: 89.48678970336914%\n","car: 99.68408346176147%\n","car: 99.69595074653625%\n","bus: 54.48129177093506%\n","bus: 72.98420071601868%\n","truck: 59.97998118400574%\n","truck: 63.871192932128906%\n","bus: 58.63416790962219%\n","truck: 59.34057831764221%\n","car: 68.24140548706055%\n","car: 94.98766660690308%\n","car: 85.82795858383179%\n","car: 98.24591279029846%\n","car: 96.58244848251343%\n","car: 99.78857040405273%\n","car: 66.33812189102173%\n","car: 99.25714135169983%\n","car: 98.69420528411865%\n","car: 99.76702332496643%\n","car: 99.64321255683899%\n","car: 96.75505757331848%\n","car: 99.45352077484131%\n","car: 68.35829019546509%\n","car: 94.78598833084106%\n","car: 95.4122245311737%\n","car: 65.0764524936676%\n","car: 92.09641218185425%\n","car: 90.01728296279907%\n","car: 75.83725452423096%\n","car: 50.12393593788147%\n","person: 74.83114004135132%\n","person: 69.03085112571716%\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[[112, 117, 116],\n","        [108, 113, 112],\n","        [103, 108, 107],\n","        ...,\n","        [148, 131, 128],\n","        [144, 127, 124],\n","        [142, 125, 122]],\n","\n","       [[ 81,  86,  85],\n","        [ 79,  84,  83],\n","        [ 77,  82,  81],\n","        ...,\n","        [147, 130, 127],\n","        [144, 127, 124],\n","        [141, 124, 121]],\n","\n","       [[ 60,  62,  62],\n","        [ 61,  63,  63],\n","        [ 63,  65,  65],\n","        ...,\n","        [146, 129, 126],\n","        [143, 126, 123],\n","        [140, 123, 120]],\n","\n","       ...,\n","\n","       [[172, 177, 180],\n","        [173, 178, 181],\n","        [174, 179, 182],\n","        ...,\n","        [185, 189, 194],\n","        [186, 190, 195],\n","        [190, 194, 199]],\n","\n","       [[171, 176, 179],\n","        [171, 176, 179],\n","        [172, 177, 180],\n","        ...,\n","        [185, 189, 194],\n","        [188, 192, 197],\n","        [192, 196, 201]],\n","\n","       [[171, 176, 179],\n","        [170, 175, 178],\n","        [171, 176, 179],\n","        ...,\n","        [188, 192, 197],\n","        [192, 196, 201],\n","        [197, 201, 206]]], dtype=uint8)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["\n","veh=[\"car\",\"bus\",\"truck\"]\n","v_num=0\n","for box in boxes:\n","        label = -1\n","        \n","        for i in range(len(labels)):\n","            if box.classes[i] > obj_thresh:\n","                label = i\n","                if(labels[i] in veh):\n","                  v_num+=1\n","print(f'Number of vehicles: {v_num}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fS8CRUZhEGog","executionInfo":{"status":"ok","timestamp":1681560779398,"user_tz":-210,"elapsed":2464,"user":{"displayName":"Hadi Vaezi","userId":"08960764307584402497"}},"outputId":"4e22116c-025a-4a26-8e0a-4dd7df6ba3af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of vehicles: 32\n"]}]},{"cell_type":"code","source":["im_pathes=['/content/drive/MyDrive/vehicle detection/weights/A.jpeg',\n","           '/content/drive/MyDrive/vehicle detection/weights/B.jpg',\n","           '/content/drive/MyDrive/vehicle detection/weights/C.jpeg',\n","           '/content/drive/MyDrive/vehicle detection/weights/D.jpeg']\n","\n","\n","\n","def boxx(im):\n","  net_h, net_w = 416, 416\n","  obj_thresh, nms_thresh = 0.5, 0.45\n","  anchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\n","  yolos = yolov3.predict(im)\n","  boxes = []\n","\n","  for i in range(len(yolos)):\n","      # decode the output of the network\n","      boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh, nms_thresh, net_h, net_w)\n","  return boxes\n","\n","def num_car(boxes,labels):\n","  veh=[\"car\",\"bus\",\"truck\"]\n","  v_num=0\n","  for box in boxes:\n","          label = -1\n","          \n","          for i in range(len(labels)):\n","              if box.classes[i] > obj_thresh:\n","                  label = i\n","                  if(labels[i] in veh):\n","                    v_num+=1\n","  return v_num\n","\n","\n","\n","def ITL(im_pathes, labels):\n","  im_A=cv2.imread(im_pathes[0])\n","  image_h, image_w, _ = im_A.shape\n","  newA = preprocess_input(im_A, net_h, net_w)\n","  bA=boxx(newA)\n","  correct_yolo_boxes(bA, image_h, image_w, net_h, net_w)\n","  do_nms(bA, nms_thresh)  \n","  num_A=num_car(bA,labels)\n","\n","  im_B=cv2.imread(im_pathes[1])\n","  image_h, image_w, _ = im_B.shape\n","  newB = preprocess_input(im_B, net_h, net_w)\n","  bB=boxx(newB)\n","  correct_yolo_boxes(bB, image_h, image_w, net_h, net_w)\n","  do_nms(bB, nms_thresh)  \n","  num_B=num_car(bB,labels)\n","\n","  im_C=cv2.imread(im_pathes[2])\n","  image_h, image_w, _ = im_C.shape\n","  newC = preprocess_input(im_C, net_h, net_w)\n","  bC=boxx(newC)\n","  correct_yolo_boxes(bC, image_h, image_w, net_h, net_w)\n","  do_nms(bC, nms_thresh)  \n","  num_C=num_car(bC,labels)\n","\n","  im_D=cv2.imread(im_pathes[3])\n","  image_h, image_w, _ = im_D.shape\n","  newD = preprocess_input(im_D, net_h, net_w)\n","  bD=boxx(newD)\n","  correct_yolo_boxes(bD, image_h, image_w, net_h, net_w)\n","  do_nms(bD, nms_thresh)  \n","  num_D=num_car(bD,labels)\n","\n","  num_total=num_A+num_B+num_C+num_D\n","  rA=num_A/num_total\n","  rB=num_B/num_total\n","  rC=num_C/num_total\n","  rD=num_D/num_total\n","  t_green_A=rA*28+5\n","  t_green_B=rB*28+5\n","  t_green_C=rC*28+5\n","  t_green_D=rD*28+5\n","  t_red_A=50-3-t_green_A\n","  t_red_B=50-3-t_green_B\n","  t_red_C=50-3-t_green_C\n","  t_red_D=50-3-t_green_D\n","  t_yello_A=3\n","  t_yello_B=3\n","  t_yello_C=3\n","  t_yello_D=3\n","  output={'Street A':{'red':t_red_A,'green':t_green_A,'yello':t_yello_A},\n","          'Street B':{'red':t_red_B,'green':t_green_B,'yello':t_yello_B},\n","          'Street C':{'red':t_red_C,'green':t_green_C,'yello':t_yello_C},\n","          'Street D':{'red':t_red_D,'green':t_green_D,'yello':t_yello_D}}\n","  return output\n","  \n","ITL(im_pathes, labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uCr1DNIrK6yN","executionInfo":{"status":"ok","timestamp":1681562002108,"user_tz":-210,"elapsed":33879,"user":{"displayName":"Hadi Vaezi","userId":"08960764307584402497"}},"outputId":"e8f540c3-6956-497e-fbd5-ac82e1642e73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 2s 2s/step\n","1/1 [==============================] - 1s 1s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["{'Street A': {'red': 37.04615384615384,\n","  'green': 9.953846153846154,\n","  'yello': 3},\n"," 'Street B': {'red': 35.107692307692304,\n","  'green': 11.892307692307693,\n","  'yello': 3},\n"," 'Street C': {'red': 34.03076923076923,\n","  'green': 12.96923076923077,\n","  'yello': 3},\n"," 'Street D': {'red': 33.815384615384616,\n","  'green': 13.184615384615386,\n","  'yello': 3}}"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["int(2.7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3jKPcjQcO28H","executionInfo":{"status":"ok","timestamp":1681500377550,"user_tz":-210,"elapsed":11,"user":{"displayName":"Hadi Vaezi","userId":"08960764307584402497"}},"outputId":"a679ef45-5496-4b69-bb0a-00b958cc0fba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":6}]}]}